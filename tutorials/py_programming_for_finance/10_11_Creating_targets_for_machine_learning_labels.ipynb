{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "875d05d8",
   "metadata": {},
   "source": [
    "## Creating targets for machine learning labels\n",
    "\n",
    "https://pythonprogramming.net/targets-for-machine-learning-labels-python-programming-for-finance/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7c6618",
   "metadata": {},
   "source": [
    "Hello and welcome to part 10 (and 11) of the Python for Finance tutorial series. In the previous tutorial, we began to build our labels for our attempt at using machine learning for investing with Python. In this tutorial, we're going to use what we did last tutorial to actually generate our labels when we're ready.\n",
    "\n",
    "Full code up to this point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "038795b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import pickle\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "def save_sp500_tickers():\n",
    "    resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "    soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "    table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "    tickers = []\n",
    "    for row in table.findAll('tr')[1:]:\n",
    "        ticker = row.findAll('td')[0].text\n",
    "        tickers.append(ticker.strip())\n",
    "        \n",
    "    with open(\"sp500tickers.pickle\",\"wb\") as f:\n",
    "        pickle.dump(tickers,f)\n",
    "        \n",
    "    return tickers\n",
    "\n",
    "\n",
    "def get_data_from_yahoo(reload_sp500=False):\n",
    "    if reload_sp500:\n",
    "        tickers = save_sp500_tickers()\n",
    "    else:\n",
    "        with open(\"sp500tickers.pickle\", \"rb\") as f:\n",
    "            tickers = pickle.load(f)\n",
    "    if not os.path.exists('stock_dfs'):\n",
    "        os.makedirs('stock_dfs')\n",
    "\n",
    "    start = dt.datetime(2010, 1, 1)\n",
    "    end = dt.datetime.now()\n",
    "    for ticker in tickers:\n",
    "        # e.g. BRK.B => BRK-B, BF.B => BF-B\n",
    "        ticker = ticker.replace('.', '-')\n",
    "        # just in case your connection breaks, we'd like to save our progress!\n",
    "        if not os.path.exists('stock_dfs/{}.csv'.format(ticker)):\n",
    "            df = yf.download(ticker, start=start, end=end)\n",
    "            df.to_csv('stock_dfs/{}.csv'.format(ticker))\n",
    "        else:\n",
    "            print('Already have {}'.format(ticker))\n",
    "\n",
    "\n",
    "def compile_data():\n",
    "    with open(\"sp500tickers.pickle\", \"rb\") as f:\n",
    "        tickers = pickle.load(f)\n",
    "\n",
    "    main_df = pd.DataFrame()\n",
    "\n",
    "    for ticker in tqdm(tickers):\n",
    "        # e.g. BRK.B => BRK-B, BF.B => BF-B\n",
    "        ticker = ticker.replace('.', '-')\n",
    "        df = pd.read_csv('stock_dfs/{}.csv'.format(ticker))\n",
    "        df.set_index('Date', inplace=True)\n",
    "\n",
    "        df.rename(columns={'Adj Close': ticker}, inplace=True)\n",
    "        df.drop(columns=['Open', 'High', 'Low', 'Close', 'Volume'], inplace=True)\n",
    "\n",
    "        if main_df.empty:\n",
    "            main_df = df\n",
    "        else:\n",
    "            main_df = main_df.join(df, how='outer')\n",
    "\n",
    "    display(main_df)\n",
    "    main_df.to_csv('sp500_joined_closes.csv')\n",
    "\n",
    "\n",
    "def visualize_data():\n",
    "    df = pd.read_csv('sp500_joined_closes.csv')\n",
    "    df_corr = df.corr(numeric_only=True)\n",
    "    display(df_corr.head())\n",
    "    df_corr.to_csv('sp500corr.csv')\n",
    "    data1 = df_corr.values\n",
    "    fig1 = plt.figure()\n",
    "    ax1 = fig1.add_subplot(111)\n",
    "\n",
    "    heatmap1 = ax1.pcolor(data1, cmap=plt.cm.RdYlGn)\n",
    "    fig1.colorbar(heatmap1)\n",
    "\n",
    "    ax1.set_xticks(np.arange(data1.shape[1]) + 0.5, minor=False)\n",
    "    ax1.set_yticks(np.arange(data1.shape[0]) + 0.5, minor=False)\n",
    "    ax1.invert_yaxis()\n",
    "    ax1.xaxis.tick_top()\n",
    "    column_labels = df_corr.columns\n",
    "    row_labels = df_corr.index\n",
    "    ax1.set_xticklabels(column_labels)\n",
    "    ax1.set_yticklabels(row_labels)\n",
    "    plt.xticks(rotation=90)\n",
    "    heatmap1.set_clim(-1, 1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def process_data_for_labels(ticker):\n",
    "    hm_days = 7\n",
    "    df = pd.read_csv('sp500_joined_closes.csv', index_col=0)\n",
    "    tickers = df.columns.values.tolist()\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    for i in range(1,hm_days+1):\n",
    "        df['{}_{}d'.format(ticker,i)] = (df[ticker].shift(-i) - df[ticker]) / df[ticker]\n",
    "\n",
    "    df.fillna(0, inplace=True)\n",
    "    return tickers, df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45868ac",
   "metadata": {},
   "source": [
    "Now we're going to create the function that creates our label. We have a lot of choices here. You might want to have something that dictates buy, sell, or hold, or maybe just buy or sell. I am going to have us do the former. Basically, if the price rises more than 2% in the next 7 days, we're going to say that's a buy. If it drops more than 2% in the next 7 days, that's a sell. If it doesn't do either of those, then it's not moving enough, and we're going to just hold whatever our position is. If we have shares in that company, we do nothing, we keep our position. If we don't have shares in that company, we do nothing, we just wait. Our function to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a340749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buy_sell_hold(*args):\n",
    "    cols = [c for c in args]\n",
    "    requirement = 0.02\n",
    "    for col in cols:\n",
    "        if col > requirement:\n",
    "            return 1\n",
    "        if col < -requirement:\n",
    "            return -1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186379cb",
   "metadata": {},
   "source": [
    "We're using [args](https://pythonprogramming.net/args-kwargs-intermediate-python-tutorial/) here so we can take any number of columns here that we want. The idea here is that we're going to [map this function to a Pandas DataFrame column](https://pythonprogramming.net/rolling-apply-mapping-functions-data-analysis-python-pandas-tutorial/), and that column will be our \"label.\" A -1 is a sell, 0 is hold, and 1 is a buy. The `*args` will be those future price change columns, and we're interested if we see movement that exceeds 2% in either direction. Do note, this isn't a totally perfect function. For example, price might go up 2%, then fall 2%, and we might not be prepared for that, but it will do for now.\n",
    "\n",
    "With that, let's actually make our features and labels! For this function, we're going to add the following import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2683dc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6027f902",
   "metadata": {},
   "source": [
    "This will let us see the distributions of classes both in our dataset and in our algorithm's predictions. We dont want to feed highly imbalanced datasets to machine learning classifiers, and we also want to see if our classifier is predicting only one class. Our next function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d584bd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_featuresets(ticker):\n",
    "#     tickers, df = process_data_for_labels(ticker)\n",
    "\n",
    "#     df['{}_target'.format(ticker)] = list(map( buy_sell_hold,\n",
    "#                                                df['{}_1d'.format(ticker)],\n",
    "#                                                df['{}_2d'.format(ticker)],\n",
    "#                                                df['{}_3d'.format(ticker)],\n",
    "#                                                df['{}_4d'.format(ticker)],\n",
    "#                                                df['{}_5d'.format(ticker)],\n",
    "#                                                df['{}_6d'.format(ticker)],\n",
    "#                                                df['{}_7d'.format(ticker)] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ba8bab",
   "metadata": {},
   "source": [
    "This function will take any ticker, create the needed dataset, and create our \"target\" column, which is our label. The target column will have either a -1, 0, or 1 for each row, based on our function and the columns we feed through. Now, we can get the distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd79f03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     vals = df['{}_target'.format(ticker)].values.tolist()\n",
    "#     str_vals = [str(i) for i in vals]\n",
    "#     print('Data spread:',Counter(str_vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b2fde3",
   "metadata": {},
   "source": [
    "Clean up our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afa31202",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     df.fillna(0, inplace=True)\n",
    "#     df = df.replace([np.inf, -np.inf], np.nan)\n",
    "#     df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d0ea66",
   "metadata": {},
   "source": [
    "We probably have some totally missing data, which we'll replace with 0. Next we probably have some infinite data, especially if we did a percent change from 0 to anything. We're going to convert infinite values to NaNs, then we're going to drop NaNs. We're **almost** ready to rumble, but right now our \"features\" are that day's prices for stocks. Just static numbers, really nothing telling at all. Instead, a better metric would be every company's percent change that day. The idea here being that some companies will change in price before others, and we can profit maybe on the laggards. We'll convert the stock prices to % changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2fcb639",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     df_vals = df[[ticker for ticker in tickers]].pct_change()\n",
    "#     df_vals = df_vals.replace([np.inf, -np.inf], 0)\n",
    "#     df_vals.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4a0cc3",
   "metadata": {},
   "source": [
    "Again, being careful about infinite numbers, and then filling any other missing data, and, now, finally, we are ready to create our features and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a24716bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     X = df_vals.values\n",
    "#     y = df['{}_target'.format(ticker)].values\n",
    "\n",
    "#     return X,y,df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4a1221",
   "metadata": {},
   "source": [
    "The capital X contains our featuresets (daily % changes for every company in the S&P 500). The lowercase y is our \"target\" or our \"label.\" Basically what we're trying to map our featuresets to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccbcf5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_featuresets(ticker):\n",
    "    tickers, df = process_data_for_labels(ticker)\n",
    "\n",
    "    df['{}_target'.format(ticker)] = list(map( buy_sell_hold,\n",
    "                                               df['{}_1d'.format(ticker)],\n",
    "                                               df['{}_2d'.format(ticker)],\n",
    "                                               df['{}_3d'.format(ticker)],\n",
    "                                               df['{}_4d'.format(ticker)],\n",
    "                                               df['{}_5d'.format(ticker)],\n",
    "                                               df['{}_6d'.format(ticker)],\n",
    "                                               df['{}_7d'.format(ticker)]))\n",
    "\n",
    "    vals = df['{}_target'.format(ticker)].values.tolist()\n",
    "    str_vals = [str(i) for i in vals]\n",
    "    print('Data spread:', Counter(str_vals))\n",
    "\n",
    "    df.fillna(0, inplace=True)\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    df_vals = df[[ticker for ticker in tickers]].pct_change()\n",
    "    df_vals = df_vals.replace([np.inf, -np.inf], 0)\n",
    "    df_vals.fillna(0, inplace=True)\n",
    "\n",
    "    X = df_vals.values\n",
    "    y = df['{}_target'.format(ticker)].values\n",
    "    return X, y, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8833a38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data spread: Counter({'1': 1334, '-1': 1138, '0': 1008})\n"
     ]
    }
   ],
   "source": [
    "X, y, df = extract_featuresets('XOM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02aa5866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2010-01-04    0\n",
       "2010-01-05    0\n",
       "2010-01-06    0\n",
       "2010-01-07    0\n",
       "2010-01-08   -1\n",
       "             ..\n",
       "2023-10-24   -1\n",
       "2023-10-25   -1\n",
       "2023-10-26    0\n",
       "2023-10-27    0\n",
       "2023-10-30    0\n",
       "Name: XOM_target, Length: 3480, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['XOM_target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09e0b5b",
   "metadata": {},
   "source": [
    "Alright, we've got features and labels, we're ready to do some machine learning, which is what we'll cover in the next tutorial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
