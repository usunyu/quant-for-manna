{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29c55367",
   "metadata": {},
   "source": [
    "## Preprocessing data to prepare for Machine Learning with stock data\n",
    "\n",
    "https://pythonprogramming.net/preprocessing-for-machine-learning-python-programming-for-finance/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534a653a",
   "metadata": {},
   "source": [
    "Hello and welcome to part 9 of the Python for Finance tutorial series. In the previous tutorials, we've covered how to pull in stock pricing data for a large number of companies, how to combine that data into one large dataset, and how to visually represent at least one relationship between all of the companies. Now, we're going to try to take this data and do some machine learning with it!\n",
    "\n",
    "The idea is to see what might happen if we took data from all of the current companies, and fed this through some sort of machine learning classifier. We know that, over time, various companies have different relationships with eachother, so, if the machine can recognize and fit these relationships, it's possible we could predict from changes in prices today, what will happen tomorrow with a specific company. Let's try!\n",
    "\n",
    "To begin, all machine learning does is take \"featuresets\" and attempts to map them to \"labels.\" Whether we're doing [K Nearest Neighbors](https://pythonprogramming.net/k-nearest-neighbors-intro-machine-learning-tutorial/) or [deep learning with neural networks](https://pythonprogramming.net/neural-networks-machine-learning-tutorial/), this remains the same. Thus, we need to convert our existing data to featuresets and labels.\n",
    "\n",
    "Our features can be other company's prices, but we're going to instead say the features are the pricing changes that day for all companies. Our label will be whether or not we actually want to buy a specific company. Let's say we're considering Exxon (XOM). What we'll do for featuresets is take into account all company percent changes that day, and those will be our features. Our label will be whether or not Exxon (XOM) rose more than x% within the next x days, where we can pick whatever we want for x. To start, let's say a company is a buy if, within the next 7 days, its price goes up more than 2% and it is a sell if the price goes down more than 2% within those 7 days.\n",
    "\n",
    "This is something we could also relatively easily make a strategy for. If the algorithm says buy, we can buy, place a 2% drop stop-loss (basically something that tells the exchange is price falls below this number / or goes above if you're shorting the company, then exit my position). Otherwise, sell the company once it has risen 2%, or you could be conservative and sell at 1% rise...etc. Regardless, you could relatively easily build a strategy from this classifier. In order to begin, we need the prices into the future for our training data.\n",
    "\n",
    "I am going to keep coding in our same script. If this is a problem to you, feel free to create a new file and import the functions we use.\n",
    "\n",
    "Full code up to this point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f97afdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import pickle\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "def save_sp500_tickers():\n",
    "    resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "    soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "    table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "    tickers = []\n",
    "    for row in table.findAll('tr')[1:]:\n",
    "        ticker = row.findAll('td')[0].text\n",
    "        tickers.append(ticker.strip())\n",
    "        \n",
    "    with open(\"sp500tickers.pickle\",\"wb\") as f:\n",
    "        pickle.dump(tickers,f)\n",
    "        \n",
    "    return tickers\n",
    "\n",
    "\n",
    "def get_data_from_yahoo(reload_sp500=False):\n",
    "    if reload_sp500:\n",
    "        tickers = save_sp500_tickers()\n",
    "    else:\n",
    "        with open(\"sp500tickers.pickle\", \"rb\") as f:\n",
    "            tickers = pickle.load(f)\n",
    "    if not os.path.exists('stock_dfs'):\n",
    "        os.makedirs('stock_dfs')\n",
    "\n",
    "    start = dt.datetime(2010, 1, 1)\n",
    "    end = dt.datetime.now()\n",
    "    for ticker in tickers:\n",
    "        # e.g. BRK.B => BRK-B, BF.B => BF-B\n",
    "        ticker = ticker.replace('.', '-')\n",
    "        # just in case your connection breaks, we'd like to save our progress!\n",
    "        if not os.path.exists('stock_dfs/{}.csv'.format(ticker)):\n",
    "            df = yf.download(ticker, start=start, end=end)\n",
    "            df.to_csv('stock_dfs/{}.csv'.format(ticker))\n",
    "        else:\n",
    "            print('Already have {}'.format(ticker))\n",
    "\n",
    "\n",
    "def compile_data():\n",
    "    with open(\"sp500tickers.pickle\", \"rb\") as f:\n",
    "        tickers = pickle.load(f)\n",
    "\n",
    "    main_df = pd.DataFrame()\n",
    "\n",
    "    for ticker in tqdm(tickers):\n",
    "        # e.g. BRK.B => BRK-B, BF.B => BF-B\n",
    "        ticker = ticker.replace('.', '-')\n",
    "        df = pd.read_csv('stock_dfs/{}.csv'.format(ticker))\n",
    "        df.set_index('Date', inplace=True)\n",
    "\n",
    "        df.rename(columns={'Adj Close': ticker}, inplace=True)\n",
    "        df.drop(columns=['Open', 'High', 'Low', 'Close', 'Volume'], inplace=True)\n",
    "\n",
    "        if main_df.empty:\n",
    "            main_df = df\n",
    "        else:\n",
    "            main_df = main_df.join(df, how='outer')\n",
    "\n",
    "    display(main_df)\n",
    "    main_df.to_csv('sp500_joined_closes.csv')\n",
    "\n",
    "\n",
    "def visualize_data():\n",
    "    df = pd.read_csv('sp500_joined_closes.csv')\n",
    "    df_corr = df.corr(numeric_only=True)\n",
    "    display(df_corr.head())\n",
    "    df_corr.to_csv('sp500corr.csv')\n",
    "    data1 = df_corr.values\n",
    "    fig1 = plt.figure()\n",
    "    ax1 = fig1.add_subplot(111)\n",
    "\n",
    "    heatmap1 = ax1.pcolor(data1, cmap=plt.cm.RdYlGn)\n",
    "    fig1.colorbar(heatmap1)\n",
    "\n",
    "    ax1.set_xticks(np.arange(data1.shape[1]) + 0.5, minor=False)\n",
    "    ax1.set_yticks(np.arange(data1.shape[0]) + 0.5, minor=False)\n",
    "    ax1.invert_yaxis()\n",
    "    ax1.xaxis.tick_top()\n",
    "    column_labels = df_corr.columns\n",
    "    row_labels = df_corr.index\n",
    "    ax1.set_xticklabels(column_labels)\n",
    "    ax1.set_yticklabels(row_labels)\n",
    "    plt.xticks(rotation=90)\n",
    "    heatmap1.set_clim(-1, 1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "# visualize_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ffbfe6",
   "metadata": {},
   "source": [
    "Continuing along, let's begin to process some data that will help us to create our labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60a6ba21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_data_for_labels(ticker):\n",
    "#     hm_days = 7\n",
    "#     df = pd.read_csv('sp500_joined_closes.csv', index_col=0)\n",
    "#     tickers = df.columns.values.tolist()\n",
    "#     df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807b4c45",
   "metadata": {},
   "source": [
    "This function will take one parameter: the `ticker` in question. Each model will be trained on a single company. Next, we want to know how many days into the future we need prices for. We're choosing 7 here. Now, we'll read in the data for the close prices for all companies that we've saved in the past, grab a list of the existing tickers, and we'll fill any missing with 0 for now. This might be something you want to change in the future, but we'll go with 0 for now. Now, we want to grab the % change values for the next 7 days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25680b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     for i in range(1,hm_days+1):\n",
    "#         df['{}_{}d'.format(ticker,i)] = (df[ticker].shift(-i) - df[ticker]) / df[ticker]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a04d2cd",
   "metadata": {},
   "source": [
    "This creates new dataframe columns for our specific ticker in question, using [string formatting](https://pythonprogramming.net/string-concatenation-formatting-intermediate-python-tutorial/) to create the custom names. The way we're getting future values is with `.shift`, which basically will shift a column up or down. In this case, we shift a negative amount, which will take that column and, if you could see it visually, it would shift that column `UP` by `i` rows. This gives us the future values i days in advanced, which we can calculate percent change against.\n",
    "\n",
    "Finally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dbb4d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     df.fillna(0, inplace=True)\n",
    "#     return tickers, df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30a612c",
   "metadata": {},
   "source": [
    "We're all set here, we'll return the tickers and the dataframe, and we're well on our way to having some featuresets that our algorithms can use to try to fit and find relationships.\n",
    "\n",
    "Our full processing function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b88e453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_for_labels(ticker):\n",
    "    hm_days = 7\n",
    "    df = pd.read_csv('sp500_joined_closes.csv', index_col=0)\n",
    "    tickers = df.columns.values.tolist()\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    for i in range(1,hm_days+1):\n",
    "        df['{}_{}d'.format(ticker,i)] = (df[ticker].shift(-i) - df[ticker]) / df[ticker]\n",
    "\n",
    "    df.fillna(0, inplace=True)\n",
    "    return tickers, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45ee01cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers, df = process_data_for_labels('XOM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07e3e3b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XOM</th>\n",
       "      <th>XOM_1d</th>\n",
       "      <th>XOM_2d</th>\n",
       "      <th>XOM_3d</th>\n",
       "      <th>XOM_4d</th>\n",
       "      <th>XOM_5d</th>\n",
       "      <th>XOM_6d</th>\n",
       "      <th>XOM_7d</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>40.983105</td>\n",
       "      <td>0.003905</td>\n",
       "      <td>0.012581</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>0.005350</td>\n",
       "      <td>0.016631</td>\n",
       "      <td>0.011569</td>\n",
       "      <td>0.007520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>41.143135</td>\n",
       "      <td>0.008643</td>\n",
       "      <td>0.005474</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.012676</td>\n",
       "      <td>0.007635</td>\n",
       "      <td>0.003601</td>\n",
       "      <td>0.003745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>41.498730</td>\n",
       "      <td>-0.003142</td>\n",
       "      <td>-0.007141</td>\n",
       "      <td>0.003999</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>-0.004999</td>\n",
       "      <td>-0.004856</td>\n",
       "      <td>-0.012996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>41.368336</td>\n",
       "      <td>-0.004012</td>\n",
       "      <td>0.007164</td>\n",
       "      <td>0.002149</td>\n",
       "      <td>-0.001862</td>\n",
       "      <td>-0.001719</td>\n",
       "      <td>-0.009885</td>\n",
       "      <td>-0.007593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>41.202381</td>\n",
       "      <td>0.011220</td>\n",
       "      <td>0.006186</td>\n",
       "      <td>0.002158</td>\n",
       "      <td>0.002302</td>\n",
       "      <td>-0.005897</td>\n",
       "      <td>-0.003596</td>\n",
       "      <td>-0.021433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-24</th>\n",
       "      <td>108.389999</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>-0.007289</td>\n",
       "      <td>-0.026202</td>\n",
       "      <td>-0.023157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-25</th>\n",
       "      <td>108.589996</td>\n",
       "      <td>-0.009117</td>\n",
       "      <td>-0.027995</td>\n",
       "      <td>-0.024956</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-26</th>\n",
       "      <td>107.599998</td>\n",
       "      <td>-0.019052</td>\n",
       "      <td>-0.015985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-27</th>\n",
       "      <td>105.550003</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-30</th>\n",
       "      <td>105.879997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3480 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   XOM    XOM_1d    XOM_2d    XOM_3d    XOM_4d    XOM_5d  \\\n",
       "Date                                                                       \n",
       "2010-01-04   40.983105  0.003905  0.012581  0.009400  0.005350  0.016631   \n",
       "2010-01-05   41.143135  0.008643  0.005474  0.001440  0.012676  0.007635   \n",
       "2010-01-06   41.498730 -0.003142 -0.007141  0.003999 -0.001000 -0.004999   \n",
       "2010-01-07   41.368336 -0.004012  0.007164  0.002149 -0.001862 -0.001719   \n",
       "2010-01-08   41.202381  0.011220  0.006186  0.002158  0.002302 -0.005897   \n",
       "...                ...       ...       ...       ...       ...       ...   \n",
       "2023-10-24  108.389999  0.001845 -0.007289 -0.026202 -0.023157  0.000000   \n",
       "2023-10-25  108.589996 -0.009117 -0.027995 -0.024956  0.000000  0.000000   \n",
       "2023-10-26  107.599998 -0.019052 -0.015985  0.000000  0.000000  0.000000   \n",
       "2023-10-27  105.550003  0.003126  0.000000  0.000000  0.000000  0.000000   \n",
       "2023-10-30  105.879997  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "              XOM_6d    XOM_7d  \n",
       "Date                            \n",
       "2010-01-04  0.011569  0.007520  \n",
       "2010-01-05  0.003601  0.003745  \n",
       "2010-01-06 -0.004856 -0.012996  \n",
       "2010-01-07 -0.009885 -0.007593  \n",
       "2010-01-08 -0.003596 -0.021433  \n",
       "...              ...       ...  \n",
       "2023-10-24  0.000000  0.000000  \n",
       "2023-10-25  0.000000  0.000000  \n",
       "2023-10-26  0.000000  0.000000  \n",
       "2023-10-27  0.000000  0.000000  \n",
       "2023-10-30  0.000000  0.000000  \n",
       "\n",
       "[3480 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['XOM', 'XOM_1d', 'XOM_2d', 'XOM_3d', 'XOM_4d', 'XOM_5d', 'XOM_6d', 'XOM_7d']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9fa8e3",
   "metadata": {},
   "source": [
    "In the next tutorial, we're going to cover how we'll go about creating our \"labels.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
